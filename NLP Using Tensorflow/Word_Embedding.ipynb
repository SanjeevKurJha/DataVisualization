{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xoq0MRc_S4pH"
   },
   "source": [
    "### IMDB Dataset [URL](http://ai.stanford.edu/~amaas/data/sentiment/) for Sentiment analysis for movies reviews \n",
    "\n",
    "### Word embedding projection [URL](http://projector.tensorflow.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "35WoXpwlS4pK"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FXfEPJcyS4pO"
   },
   "source": [
    "### Install the tenser flow dataset using below pip code\n",
    "pip install -q tensorflow-datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "weieOHW9S4pP"
   },
   "source": [
    "### Import Imdb review dataset from tensorflow library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6bTJwkVSS4pQ"
   },
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tf_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PY3Kku3PS4pU"
   },
   "outputs": [],
   "source": [
    "imdb,info=tf_ds.load(\"imdb_reviews\",with_info=True,as_supervised=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fY7RQKNqS4pX"
   },
   "source": [
    "### Divide the dataset into training and testing set 25k on train and 25 k on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KLWMEoauS4pY"
   },
   "outputs": [],
   "source": [
    "data_train,data_test=imdb['train'],imdb['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eGAzwnorS4pc"
   },
   "outputs": [],
   "source": [
    "x_train=[] # Sentance of review of training data (data_train)\n",
    "y_train=[] # label of review of training data (data_train)\n",
    "x_test=[] # Sentance of review of testing data (data_test)\n",
    "y_test=[] # label of review of testing data (data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Teg2x1qQS4pg"
   },
   "source": [
    "### Run the for loop and append each sentance and lables in array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "04KU0D3LS4ph"
   },
   "outputs": [],
   "source": [
    "for x,y in data_train:\n",
    "    x_train.append(str(x.numpy()))\n",
    "    y_train.append(str(y.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dGTxP2nGS4pk"
   },
   "outputs": [],
   "source": [
    "for x,y in data_test:\n",
    "    x_test.append(str(x.numpy()))\n",
    "    y_test.append(str(y.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "__RZ-CdGS4pn"
   },
   "source": [
    "### Converting all the labels(y_train,y_test) into numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K9uILGfMS4po"
   },
   "outputs": [],
   "source": [
    "y_train_final=np.array(y_train)\n",
    "y_test_final=np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Se0YVJKRS4ps",
    "outputId": "23ef6934-eaed-4d16-d1d3-1b59c1c3e01b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<U1')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_final.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EDUq-UGnS4pw"
   },
   "outputs": [],
   "source": [
    "y_train_final=y_train_final.astype('int32') \n",
    "y_test_final=y_test_final.astype('int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZaOuvbe1S4p2"
   },
   "source": [
    "### Declearing the important variable for word imbedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BqaZTfj-S4p3"
   },
   "outputs": [],
   "source": [
    "vocab_size=15000\n",
    "embed_dim=20\n",
    "max_len=140\n",
    "trunc_type='post'\n",
    "oov_tok=\"<OOV>\"\n",
    "num_epochs = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nWzcG0vBS4p6"
   },
   "source": [
    "### Tokenize the sentance into word  and Pad the data to form the same length of sequience of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "molSXUPGS4p8"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Twc3-OA8S4p_"
   },
   "outputs": [],
   "source": [
    "tokenizer=Tokenizer(num_words=vocab_size,oov_token=oov_tok)\n",
    "#fit_on_texts will take the data and encode it\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "#it will provide the word index property in dectionary form\n",
    "word_index=tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EFqq1y22S4qF"
   },
   "outputs": [],
   "source": [
    "x_train_sequences=tokenizer.texts_to_sequences(x_train)\n",
    "x_train_padded=pad_sequences(x_train_sequences,maxlen=max_len,truncating=trunc_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xdI27iwJS4qK"
   },
   "outputs": [],
   "source": [
    "x_test_sequences=tokenizer.texts_to_sequences(x_test)\n",
    "x_test_padded=pad_sequences(x_test_sequences,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qUZYV-IXS4qN"
   },
   "source": [
    "### Building a keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c6WJZ4zNS4qO"
   },
   "outputs": [],
   "source": [
    "model=tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size,embed_dim,input_length=max_len),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(6,activation=\"tanh\"),\n",
    "    tf.keras.layers.Dense(1,activation=\"sigmoid\")    \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DfYNSiI3S4qS"
   },
   "source": [
    "### How can we use the vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "zNCTTHwlS4qT",
    "outputId": "5f9d5c02-c55c-4220-885b-e48ea5a1de0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 140, 20)           300000    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2800)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 16806     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 316,813\n",
      "Trainable params: 316,813\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, decay=0.001)\n",
    "model.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dVebmUQrS4qW"
   },
   "outputs": [],
   "source": [
    "earlyStopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10, min_delta=0.01) \n",
    "\n",
    "modelCheckpoint = ModelCheckpoint('word_embedding.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "UO5oaNuwS4qY",
    "outputId": "3c85fb34-68d9-4522-9eef-7bb6a39015a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/150\n",
      "WARNING:tensorflow:From C:\\Users\\Sanjeev\\Anaconda3\\envs\\convo\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Sanjeev\\Anaconda3\\envs\\convo\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24992/25000 [============================>.] - ETA: 0s - loss: 0.6897 - acc: 0.5377\n",
      "Epoch 00001: val_acc improved from -inf to 0.58056, saving model to word_embedding.hdf5\n",
      "25000/25000 [==============================] - 6s 241us/sample - loss: 0.6897 - acc: 0.5378 - val_loss: 0.6858 - val_acc: 0.5806\n",
      "Epoch 2/150\n",
      "24960/25000 [============================>.] - ETA: 0s - loss: 0.6696 - acc: 0.6630\n",
      "Epoch 00002: val_acc improved from 0.58056 to 0.66516, saving model to word_embedding.hdf5\n",
      "25000/25000 [==============================] - 5s 209us/sample - loss: 0.6696 - acc: 0.6631 - val_loss: 0.6621 - val_acc: 0.6652\n",
      "Epoch 3/150\n",
      "24704/25000 [============================>.] - ETA: 0s - loss: 0.6330 - acc: 0.7198\n",
      "Epoch 00003: val_acc improved from 0.66516 to 0.71828, saving model to word_embedding.hdf5\n",
      "25000/25000 [==============================] - 5s 191us/sample - loss: 0.6327 - acc: 0.7204 - val_loss: 0.6222 - val_acc: 0.7183\n",
      "Epoch 4/150\n",
      "24768/25000 [============================>.] - ETA: 0s - loss: 0.5877 - acc: 0.7567\n",
      "Epoch 00004: val_acc improved from 0.71828 to 0.75380, saving model to word_embedding.hdf5\n",
      "25000/25000 [==============================] - 5s 192us/sample - loss: 0.5877 - acc: 0.7562 - val_loss: 0.5807 - val_acc: 0.7538\n",
      "Epoch 5/150\n",
      "24896/25000 [============================>.] - ETA: 0s - loss: 0.5465 - acc: 0.7847\n",
      "Epoch 00005: val_acc improved from 0.75380 to 0.77556, saving model to word_embedding.hdf5\n",
      "25000/25000 [==============================] - 5s 217us/sample - loss: 0.5465 - acc: 0.7846 - val_loss: 0.5451 - val_acc: 0.7756\n",
      "Epoch 6/150\n",
      "24672/25000 [============================>.] - ETA: 0s - loss: 0.5125 - acc: 0.8035\n",
      "Epoch 00006: val_acc improved from 0.77556 to 0.79456, saving model to word_embedding.hdf5\n",
      "25000/25000 [==============================] - 5s 192us/sample - loss: 0.5121 - acc: 0.8041 - val_loss: 0.5162 - val_acc: 0.7946\n",
      "Epoch 7/150\n",
      "24640/25000 [============================>.] - ETA: 0s - loss: 0.4843 - acc: 0.8185\n",
      "Epoch 00007: val_acc improved from 0.79456 to 0.80612, saving model to word_embedding.hdf5\n",
      "25000/25000 [==============================] - 5s 200us/sample - loss: 0.4841 - acc: 0.8188 - val_loss: 0.4935 - val_acc: 0.8061\n",
      "Epoch 8/150\n",
      "24992/25000 [============================>.] - ETA: 0s - loss: 0.4613 - acc: 0.8295\n",
      "Epoch 00008: val_acc improved from 0.80612 to 0.81500, saving model to word_embedding.hdf5\n",
      "25000/25000 [==============================] - 5s 213us/sample - loss: 0.4613 - acc: 0.8294 - val_loss: 0.4742 - val_acc: 0.8150\n",
      "Epoch 9/150\n",
      "24800/25000 [============================>.] - ETA: 0s - loss: 0.4424 - acc: 0.8376\n",
      "Epoch 00009: val_acc improved from 0.81500 to 0.82008, saving model to word_embedding.hdf5\n",
      "25000/25000 [==============================] - 5s 198us/sample - loss: 0.4425 - acc: 0.8376 - val_loss: 0.4588 - val_acc: 0.8201\n",
      "Epoch 10/150\n",
      "24992/25000 [============================>.] - ETA: 0s - loss: 0.4269 - acc: 0.8442\n",
      "Epoch 00010: val_acc improved from 0.82008 to 0.82320, saving model to word_embedding.hdf5\n",
      "25000/25000 [==============================] - 5s 194us/sample - loss: 0.4269 - acc: 0.8443 - val_loss: 0.4458 - val_acc: 0.8232\n",
      "Epoch 11/150\n",
      "24896/25000 [============================>.] - ETA: 0s - loss: 0.4135 - acc: 0.8488\n",
      "Epoch 00011: val_acc improved from 0.82320 to 0.82716, saving model to word_embedding.hdf5\n",
      "25000/25000 [==============================] - 5s 215us/sample - loss: 0.4136 - acc: 0.8488 - val_loss: 0.4353 - val_acc: 0.8272\n",
      "Epoch 12/150\n",
      "24832/25000 [============================>.] - ETA: 0s - loss: 0.4024 - acc: 0.8529\n",
      "Epoch 00012: val_acc improved from 0.82716 to 0.82916, saving model to word_embedding.hdf5\n",
      "25000/25000 [==============================] - 5s 195us/sample - loss: 0.4023 - acc: 0.8531 - val_loss: 0.4264 - val_acc: 0.8292\n",
      "Epoch 13/150\n",
      "24832/25000 [============================>.] - ETA: 0s - loss: 0.3923 - acc: 0.8569\n",
      "Epoch 00013: val_acc improved from 0.82916 to 0.83228, saving model to word_embedding.hdf5\n",
      "25000/25000 [==============================] - 5s 198us/sample - loss: 0.3924 - acc: 0.8568 - val_loss: 0.4187 - val_acc: 0.8323\n",
      "Epoch 14/150\n",
      "24928/25000 [============================>.] - ETA: 0s - loss: 0.3836 - acc: 0.8601\n",
      "Epoch 00014: val_acc improved from 0.83228 to 0.83464, saving model to word_embedding.hdf5\n",
      "25000/25000 [==============================] - 5s 217us/sample - loss: 0.3837 - acc: 0.8600 - val_loss: 0.4119 - val_acc: 0.8346\n",
      "Epoch 15/150\n",
      "24864/25000 [============================>.] - ETA: 0s - loss: 0.3760 - acc: 0.8624\n",
      "Epoch 00015: val_acc improved from 0.83464 to 0.83704, saving model to word_embedding.hdf5\n",
      "25000/25000 [==============================] - 5s 197us/sample - loss: 0.3761 - acc: 0.8624 - val_loss: 0.4059 - val_acc: 0.8370\n",
      "Epoch 16/150\n",
      "24896/25000 [============================>.] - ETA: 0s - loss: 0.3690 - acc: 0.8644\n",
      "Epoch 00016: val_acc improved from 0.83704 to 0.83820, saving model to word_embedding.hdf5\n",
      "25000/25000 [==============================] - 5s 198us/sample - loss: 0.3692 - acc: 0.8644 - val_loss: 0.4006 - val_acc: 0.8382\n",
      "Epoch 17/150\n",
      "24832/25000 [============================>.] - ETA: 0s - loss: 0.3629 - acc: 0.8672\n",
      "Epoch 00017: val_acc improved from 0.83820 to 0.84012, saving model to word_embedding.hdf5\n",
      "25000/25000 [==============================] - 5s 199us/sample - loss: 0.3630 - acc: 0.8669 - val_loss: 0.3958 - val_acc: 0.8401\n",
      "Epoch 18/150\n",
      "24864/25000 [============================>.] - ETA: 0s - loss: 0.3573 - acc: 0.8690\n",
      "Epoch 00018: val_acc improved from 0.84012 to 0.84228, saving model to word_embedding.hdf5\n",
      "25000/25000 [==============================] - 5s 216us/sample - loss: 0.3573 - acc: 0.8689 - val_loss: 0.3915 - val_acc: 0.8423\n",
      "Epoch 19/150\n",
      "24608/25000 [============================>.] - ETA: 0s - loss: 0.3524 - acc: 0.8710\n",
      "Epoch 00019: val_acc improved from 0.84228 to 0.84292, saving model to word_embedding.hdf5\n",
      "25000/25000 [==============================] - 5s 199us/sample - loss: 0.3522 - acc: 0.8711 - val_loss: 0.3879 - val_acc: 0.8429\n",
      "Epoch 20/150\n",
      "24768/25000 [============================>.] - ETA: 0s - loss: 0.3474 - acc: 0.8727\n",
      "Epoch 00020: val_acc improved from 0.84292 to 0.84368, saving model to word_embedding.hdf5\n",
      "25000/25000 [==============================] - 5s 202us/sample - loss: 0.3474 - acc: 0.8726 - val_loss: 0.3846 - val_acc: 0.8437\n",
      "Epoch 21/150\n",
      "24864/25000 [============================>.] - ETA: 0s - loss: 0.3432 - acc: 0.8738\n",
      "Epoch 00021: val_acc improved from 0.84368 to 0.84480, saving model to word_embedding.hdf5\n",
      "25000/25000 [==============================] - 6s 222us/sample - loss: 0.3430 - acc: 0.8739 - val_loss: 0.3814 - val_acc: 0.8448\n",
      "Epoch 22/150\n",
      "24864/25000 [============================>.] - ETA: 0s - loss: 0.3388 - acc: 0.8754\n",
      "Epoch 00022: val_acc improved from 0.84480 to 0.84568, saving model to word_embedding.hdf5\n",
      "25000/25000 [==============================] - 5s 202us/sample - loss: 0.3389 - acc: 0.8753 - val_loss: 0.3784 - val_acc: 0.8457\n",
      "Epoch 23/150\n",
      "24768/25000 [============================>.] - ETA: 0s - loss: 0.3352 - acc: 0.8773\n",
      "Epoch 00023: val_acc improved from 0.84568 to 0.84668, saving model to word_embedding.hdf5\n",
      "25000/25000 [==============================] - 5s 206us/sample - loss: 0.3351 - acc: 0.8774 - val_loss: 0.3757 - val_acc: 0.8467\n",
      "Epoch 24/150\n",
      "24768/25000 [============================>.] - ETA: 0s - loss: 0.3316 - acc: 0.8786\n",
      "Epoch 00024: val_acc improved from 0.84668 to 0.84752, saving model to word_embedding.hdf5\n",
      "25000/25000 [==============================] - 6s 222us/sample - loss: 0.3315 - acc: 0.8786 - val_loss: 0.3733 - val_acc: 0.8475\n",
      "Epoch 25/150\n",
      "24928/25000 [============================>.] - ETA: 0s - loss: 0.3281 - acc: 0.8802\n",
      "Epoch 00025: val_acc improved from 0.84752 to 0.84776, saving model to word_embedding.hdf5\n",
      "25000/25000 [==============================] - 5s 209us/sample - loss: 0.3282 - acc: 0.8802 - val_loss: 0.3711 - val_acc: 0.8478\n",
      "Epoch 26/150\n",
      "24832/25000 [============================>.] - ETA: 0s - loss: 0.3250 - acc: 0.8817\n",
      "Epoch 00026: val_acc improved from 0.84776 to 0.84888, saving model to word_embedding.hdf5\n",
      "25000/25000 [==============================] - 5s 203us/sample - loss: 0.3250 - acc: 0.8817 - val_loss: 0.3688 - val_acc: 0.8489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/150\n",
      "24576/25000 [============================>.] - ETA: 0s - loss: 0.3217 - acc: 0.8829\n",
      "Epoch 00027: val_acc improved from 0.84888 to 0.84904, saving model to word_embedding.hdf5\n",
      "25000/25000 [==============================] - 7s 276us/sample - loss: 0.3220 - acc: 0.8830 - val_loss: 0.3671 - val_acc: 0.8490\n",
      "Epoch 28/150\n",
      "24704/25000 [============================>.] - ETA: 0s - loss: 0.3192 - acc: 0.8835\n",
      "Epoch 00028: val_acc improved from 0.84904 to 0.85020, saving model to word_embedding.hdf5\n",
      "25000/25000 [==============================] - 5s 191us/sample - loss: 0.3192 - acc: 0.8835 - val_loss: 0.3651 - val_acc: 0.8502\n",
      "Epoch 29/150\n",
      "24832/25000 [============================>.] - ETA: 0s - loss: 0.3162 - acc: 0.8847\n",
      "Epoch 00029: val_acc improved from 0.85020 to 0.85080, saving model to word_embedding.hdf5\n",
      "25000/25000 [==============================] - 5s 195us/sample - loss: 0.3165 - acc: 0.8843 - val_loss: 0.3634 - val_acc: 0.8508\n",
      "Epoch 30/150\n",
      "24832/25000 [============================>.] - ETA: 0s - loss: 0.3142 - acc: 0.8856\n",
      "Epoch 00030: val_acc improved from 0.85080 to 0.85128, saving model to word_embedding.hdf5\n",
      "25000/25000 [==============================] - 5s 209us/sample - loss: 0.3139 - acc: 0.8858 - val_loss: 0.3616 - val_acc: 0.8513\n",
      "Epoch 31/150\n",
      "24896/25000 [============================>.] - ETA: 0s - loss: 0.3116 - acc: 0.8863\n",
      "Epoch 00031: val_acc improved from 0.85128 to 0.85156, saving model to word_embedding.hdf5\n",
      "25000/25000 [==============================] - 5s 199us/sample - loss: 0.3115 - acc: 0.8864 - val_loss: 0.3601 - val_acc: 0.8516\n",
      "Epoch 32/150\n",
      "24992/25000 [============================>.] - ETA: 0s - loss: 0.3092 - acc: 0.8875\n",
      "Epoch 00032: val_acc improved from 0.85156 to 0.85204, saving model to word_embedding.hdf5\n",
      "25000/25000 [==============================] - 5s 198us/sample - loss: 0.3092 - acc: 0.8876 - val_loss: 0.3588 - val_acc: 0.8520\n",
      "Epoch 33/150\n",
      "24800/25000 [============================>.] - ETA: 0s - loss: 0.3071 - acc: 0.8886\n",
      "Epoch 00033: val_acc improved from 0.85204 to 0.85224, saving model to word_embedding.hdf5\n",
      "25000/25000 [==============================] - 5s 213us/sample - loss: 0.3070 - acc: 0.8886 - val_loss: 0.3574 - val_acc: 0.8522\n",
      "Epoch 34/150\n",
      "24832/25000 [============================>.] - ETA: 0s - loss: 0.3050 - acc: 0.8893\n",
      "Epoch 00034: val_acc improved from 0.85224 to 0.85264, saving model to word_embedding.hdf5\n",
      "25000/25000 [==============================] - 5s 195us/sample - loss: 0.3048 - acc: 0.8894 - val_loss: 0.3561 - val_acc: 0.8526\n",
      "Epoch 35/150\n",
      "24704/25000 [============================>.] - ETA: 0s - loss: 0.3025 - acc: 0.8904\n",
      "Epoch 00035: val_acc improved from 0.85264 to 0.85324, saving model to word_embedding.hdf5\n",
      "25000/25000 [==============================] - 5s 200us/sample - loss: 0.3028 - acc: 0.8902 - val_loss: 0.3548 - val_acc: 0.8532\n",
      "Epoch 36/150\n",
      "24736/25000 [============================>.] - ETA: 0s - loss: 0.3008 - acc: 0.8915\n",
      "Epoch 00036: val_acc improved from 0.85324 to 0.85336, saving model to word_embedding.hdf5\n",
      "25000/25000 [==============================] - 5s 218us/sample - loss: 0.3008 - acc: 0.8914 - val_loss: 0.3537 - val_acc: 0.8534\n",
      "Epoch 37/150\n",
      "24672/25000 [============================>.] - ETA: 0s - loss: 0.2991 - acc: 0.8919\n",
      "Epoch 00037: val_acc improved from 0.85336 to 0.85360, saving model to word_embedding.hdf5\n",
      "25000/25000 [==============================] - 5s 197us/sample - loss: 0.2989 - acc: 0.8920 - val_loss: 0.3526 - val_acc: 0.8536\n",
      "Epoch 38/150\n",
      "24704/25000 [============================>.] - ETA: 0s - loss: 0.2968 - acc: 0.8930\n",
      "Epoch 00038: val_acc improved from 0.85360 to 0.85412, saving model to word_embedding.hdf5\n",
      "25000/25000 [==============================] - 5s 198us/sample - loss: 0.2971 - acc: 0.8926 - val_loss: 0.3515 - val_acc: 0.8541\n",
      "Epoch 39/150\n",
      "24832/25000 [============================>.] - ETA: 0s - loss: 0.2955 - acc: 0.8929\n",
      "Epoch 00039: val_acc did not improve from 0.85412\n",
      "25000/25000 [==============================] - 5s 219us/sample - loss: 0.2953 - acc: 0.8930 - val_loss: 0.3507 - val_acc: 0.8541\n",
      "Epoch 40/150\n",
      "24992/25000 [============================>.] - ETA: 0s - loss: 0.2936 - acc: 0.8938\n",
      "Epoch 00040: val_acc improved from 0.85412 to 0.85440, saving model to word_embedding.hdf5\n",
      "25000/25000 [==============================] - 5s 199us/sample - loss: 0.2936 - acc: 0.8938 - val_loss: 0.3496 - val_acc: 0.8544\n",
      "Epoch 41/150\n",
      "24704/25000 [============================>.] - ETA: 0s - loss: 0.2919 - acc: 0.8947\n",
      "Epoch 00041: val_acc improved from 0.85440 to 0.85488, saving model to word_embedding.hdf5\n",
      "25000/25000 [==============================] - 5s 198us/sample - loss: 0.2920 - acc: 0.8946 - val_loss: 0.3486 - val_acc: 0.8549\n",
      "Epoch 42/150\n",
      "24992/25000 [============================>.] - ETA: 0s - loss: 0.2904 - acc: 0.8949\n",
      "Epoch 00042: val_acc did not improve from 0.85488\n",
      "25000/25000 [==============================] - 5s 218us/sample - loss: 0.2904 - acc: 0.8949 - val_loss: 0.3477 - val_acc: 0.8548\n",
      "Epoch 43/150\n",
      "24992/25000 [============================>.] - ETA: 0s - loss: 0.2888 - acc: 0.8956\n",
      "Epoch 00043: val_acc improved from 0.85488 to 0.85536, saving model to word_embedding.hdf5\n",
      "25000/25000 [==============================] - 5s 199us/sample - loss: 0.2888 - acc: 0.8956 - val_loss: 0.3469 - val_acc: 0.8554\n",
      "Epoch 44/150\n",
      "24896/25000 [============================>.] - ETA: 0s - loss: 0.2873 - acc: 0.8961\n",
      "Epoch 00044: val_acc improved from 0.85536 to 0.85560, saving model to word_embedding.hdf5\n",
      "25000/25000 [==============================] - 5s 204us/sample - loss: 0.2873 - acc: 0.8961 - val_loss: 0.3460 - val_acc: 0.8556\n",
      "Epoch 45/150\n",
      "24992/25000 [============================>.] - ETA: 0s - loss: 0.2858 - acc: 0.8966\n",
      "Epoch 00045: val_acc improved from 0.85560 to 0.85608, saving model to word_embedding.hdf5\n",
      "25000/25000 [==============================] - 6s 223us/sample - loss: 0.2859 - acc: 0.8966 - val_loss: 0.3453 - val_acc: 0.8561\n",
      "Epoch 46/150\n",
      "24768/25000 [============================>.] - ETA: 0s - loss: 0.2848 - acc: 0.8970\n",
      "Epoch 00046: val_acc improved from 0.85608 to 0.85636, saving model to word_embedding.hdf5\n",
      "25000/25000 [==============================] - 5s 202us/sample - loss: 0.2845 - acc: 0.8973 - val_loss: 0.3446 - val_acc: 0.8564\n",
      "Epoch 47/150\n",
      "24832/25000 [============================>.] - ETA: 0s - loss: 0.2834 - acc: 0.8978\n",
      "Epoch 00047: val_acc improved from 0.85636 to 0.85664, saving model to word_embedding.hdf5\n",
      "25000/25000 [==============================] - 5s 197us/sample - loss: 0.2831 - acc: 0.8980 - val_loss: 0.3438 - val_acc: 0.8566\n",
      "Epoch 48/150\n",
      "24768/25000 [============================>.] - ETA: 0s - loss: 0.2816 - acc: 0.8989\n",
      "Epoch 00048: val_acc improved from 0.85664 to 0.85700, saving model to word_embedding.hdf5\n",
      "25000/25000 [==============================] - 6s 223us/sample - loss: 0.2818 - acc: 0.8986 - val_loss: 0.3431 - val_acc: 0.8570\n",
      "Epoch 00048: early stopping\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_train_padded, y_train_final,batch_size = 32,callbacks=[earlyStopping,modelCheckpoint], epochs=num_epochs, validation_data=(x_test_padded, y_test_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dnfXLOujVEd5"
   },
   "outputs": [],
   "source": [
    "#history=model.fit(x_train_padded, y_train_final,epochs=num_epochs, validation_data=(x_test_padded, y_test_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "colab_type": "code",
    "id": "ue16s38tS4qb",
    "outputId": "8b392902-f4af-469b-90b6-144003953711"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot \n",
    "pyplot.plot(history.history['loss'], label='Training') \n",
    "pyplot.plot(history.history['val_loss'], label='Validation') \n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "u7n_U-sZS4qf",
    "outputId": "f80cd175-ab1f-46db-bc0b-8b55fad672c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 20)\n"
     ]
    }
   ],
   "source": [
    "e = model.layers[0]\n",
    "weights = e.get_weights()[0]\n",
    "print(weights.shape) # shape: (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "N5zt2mjwS4qi",
    "outputId": "7d86580d-9701-421f-c0e5-c6f63fcdfdc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b perhaps because i was so young innocent and brainwashed when i saw it this movie was the cause of many sleepless nights for me i haven't seen it since i was in seventh grade at a <OOV> school so i am not sure what effect it would have on me now however i will say that it left an impression on me and most of my friends it did serve its purpose at least until we were old enough and knowledgeable enough to analyze and create our own opinions i was particularly terrified of what the newly converted post rapture christians had to endure when not receiving the mark of the beast i don't want to spoil the movie for those who haven't seen it so i will not mention details of the scenes but i can still picture\n",
      "b\"Perhaps because I was so young, innocent and BRAINWASHED when I saw it, this movie was the cause of many sleepless nights for me. I haven't seen it since I was in seventh grade at a Presbyterian school, so I am not sure what effect it would have on me now. However, I will say that it left an impression on me... and most of my friends. It did serve its purpose, at least until we were old enough and knowledgeable enough to analyze and create our own opinions. I was particularly terrified of what the newly-converted post-rapture Christians had to endure when not receiving the mark of the beast. I don't want to spoil the movie for those who haven't seen it so I will not mention details of the scenes, but I can still picture them in my head... and it's been 19 years.\"\n"
     ]
    }
   ],
   "source": [
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "def decode_review(text):\n",
    "    return ' '.join([reverse_word_index.get(i, '?') for i in text])\n",
    "\n",
    "print(decode_review(x_train_padded[1]))\n",
    "print(x_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8rdQHckSS4qk"
   },
   "source": [
    "### here we are just revesing the order of word and number (word:number to number:word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dhFQq4B9S4qm"
   },
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "out_v = io.open('vecs.tsv', 'w', encoding='utf-8')\n",
    "out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n",
    "for word_num in range(1, vocab_size):\n",
    "  word = reverse_word_index[word_num]\n",
    "  embeddings = weights[word_num]\n",
    "  out_m.write(word + \"\\n\")\n",
    "  out_v.write('\\t'.join([str(x) for x in embeddings]) + \"\\n\")\n",
    "out_v.close()\n",
    "out_m.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eGvcxaIjS4qo",
    "outputId": "16c2d90f-be4d-4d02-f925-e045e67b510f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11], [], [790], [2012], [11], [2920], [2188], [], [790], [2012], [11], [579], [], [11], [579], [], [1277], [1003], [1003], [960], []]\n"
     ]
    }
   ],
   "source": [
    "sentence = \"I think this is good.\"\n",
    "sequence = tokenizer.texts_to_sequences(sentence)\n",
    "print(sequence)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Word_Embedding.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
